new_cluster: &new_cluster
  new_cluster:
    num_workers: 0
    spark_version: 15.3.x-cpu-ml-scala2.12
    node_type_id: Standard_DS3_v2
    spark_conf:
      spark.databricks.cluster.profile: singleNode
      spark.master: local[*, 4]
    custom_tags:
      clusterSource: mlops-stacks_0.4
      ResourceClass: SingleNode

common_permissions: &permissions
  permissions:
    - level: CAN_VIEW
      group_name: dsml-all

resources:
  jobs:
    batch_inference_job:
      name: ${bundle.target}-mlops_poc-batch-inference-job
      tasks:
        - task_key: batch_inference_job
          <<: *new_cluster
          notebook_task:
            notebook_path: ../deployment/batch_inference/notebooks/BatchInference.py
            base_parameters:
              env: ${bundle.target}
              input_table_name: ${bundle.target}.mlops_poc.feature_store_inference_input  # TODO: create input table for inference
              output_table_name: ${bundle.target}.mlops_poc.predictions
              model_name: ${bundle.target}.mlops_poc.${var.model_name}
              # git source information of current ML resource deployment. It will be persisted as part of the workflow run
              git_source_info: url:${bundle.git.origin_url}; branch:${bundle.git.branch}; commit:${bundle.git.commit}

      # schedule:
      #   quartz_cron_expression: "0 0 11 * * ?" # daily at 11am
      #   timezone_id: UTC
      <<: *permissions
      # If you want to turn on notifications for this job, please uncomment the below code,
      # and provide a list of emails to the on_failure argument.
      #
      #  email_notifications:
      #    on_failure:
      #      - first@company.com
      #      - second@company.com
